{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the kaggle machine learning tutorial to improve solution for 'Housing Prices Competition for Kaggle Learn Users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './train.csv'\n",
    "test_file = './test.csv'\n",
    "data = pd.read_csv(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target object and call it y\n",
    "y = data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22731.7721267\n"
     ]
    }
   ],
   "source": [
    "# Random forest with only numerical values\n",
    "pipeline1 = make_pipeline(SimpleImputer(), RandomForestRegressor(random_state=1, n_estimators=100))\n",
    "scores1 = cross_val_score(pipeline1, X, y, scoring='neg_mean_absolute_error',cv=10)\n",
    "print(abs(scores1.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_cat = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd','LotShape']\n",
    "#X_cat = data[features_cat]\n",
    "#X_cat = pd.get_dummies(X_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all features here\n",
    "X_cat = data.drop(['SalePrice'], axis=1)\n",
    "X_cat = pd.get_dummies(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17561.3441986\n"
     ]
    }
   ],
   "source": [
    "pipeline2 = make_pipeline(SimpleImputer(), RandomForestRegressor(random_state=1, n_estimators=100))\n",
    "scores2 = cross_val_score(pipeline2, X_cat, y, scoring='neg_mean_absolute_error', cv=10)\n",
    "print(abs(scores2.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23467.2210312\n"
     ]
    }
   ],
   "source": [
    "# need to find the number of estimators again after switching to the scikit-learn version \n",
    "\n",
    "xgmodel = GradientBoostingRegressor(n_estimators=100, learning_rate=0.05)\n",
    "pipeline3 = make_pipeline(SimpleImputer(), xgmodel)\n",
    "scores3 = cross_val_score(pipeline3, X, y, scoring='neg_mean_absolute_error', cv=10)\n",
    "print(abs(scores3.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to figure out the number of estimators in the xgboost model\n",
    "def get_score_model_xg(xgmodel, train_X, val_X, train_y, val_Y):\n",
    "\n",
    "    tr_X, ts_X, tr_y, ts_y = train_test_split(train_X, train_y, test_size=0.33, random_state=1)\n",
    "    xgmodel.fit(tr_X, tr_y, n_iter_no_change=5, \n",
    "             eval_set=[(ts_X, ts_y)], verbose=False)\n",
    "    \n",
    "    best_ntree.append(xgmodel.best_ntree_limit)\n",
    "    \n",
    "    \n",
    "    # Make validation predictions and calculate mean absolute error\n",
    "    val_predictions = xgmodel.predict(val_X)\n",
    "    val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "    return val_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model I have so far with all the data\n",
    "#modelxg = XGBRegressor(n_estimators=35, learning_rate=0.05)\n",
    "#model.fit(X,y)\n",
    "\n",
    "\n",
    "#xgbm = GradientBoostingRegressor(n_estimators=100,learning_rate=0.05)\n",
    "#xgbm.fit(X,y)\n",
    "\n",
    "\n",
    "pipl = make_pipeline(SimpleImputer(), RandomForestRegressor(random_state=1, n_estimators=100))\n",
    "#pipl.fit(X_cat,y) # doing this later, since we need to select the common columns from train and test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data, process it, predict and output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test data\n",
    "test_data = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any processing needed on the data\n",
    "#test_X = test_data[features]\n",
    "test_X_cat = pd.get_dummies(test_data)\n",
    "#test_X_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we have the same columns in both sets, otherwise errors\n",
    "final_train_X_cat, final_test_X_cat = X_cat.align(test_X_cat, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and make predictions\n",
    "pipl.fit(final_train_X_cat,y)\n",
    "test_preds = pipl.predict(final_test_X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "gbrt has to be an instance of BaseGradientBoosting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-554-83089a4171f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                    \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0;31m# raw predictors data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                    \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LotArea'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'YearBuilt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1stFlrSF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2ndFlrSF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FullBath'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BedroomAbvGr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TotRmsAbvGrd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# labels on graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                    grid_resolution=8) # number of values to plot on x axis\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/ensemble/partial_dependence.py\u001b[0m in \u001b[0;36mplot_partial_dependence\u001b[0;34m(gbrt, X, features, feature_names, label, n_cols, grid_resolution, percentiles, n_jobs, verbose, ax, line_kw, contour_kw, **fig_kw)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseGradientBoosting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gbrt has to be an instance of BaseGradientBoosting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: gbrt has to be an instance of BaseGradientBoosting"
     ]
    }
   ],
   "source": [
    "# Partial dependence plots for sanity checks\n",
    "# only works for gradient boosted stuff\n",
    "# doesn't seem to be working with the pipeline :(\n",
    "pipeline3.fit(final_train_X_cat,y)\n",
    "my_plots = plot_partial_dependence(pipeline3,       \n",
    "                                   features=[6], # column numbers of plots we want to show\n",
    "                                   X=X,            # raw predictors data.\n",
    "                                   feature_names=['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd'], # labels on graphs\n",
    "                                   grid_resolution=8) # number of values to plot on x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
